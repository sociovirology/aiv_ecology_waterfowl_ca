# Script: aiv_detection_environment_analysis.R
# This file is an R script that couples sequencing information with sample information to arive at the main conclusions in the manuscript
# NOTE: This file depends on minion_demultiplexing_flu_assignment.sh. Run that script first!

#This script is part of the following manuscript:
#Analysis of MinION sequence data from water and sediment samples for avian influenza detection in California wetlands
#This github repository includes code (and links to data) from the manuscript:
#"Linking remote sensing for targeted surveillance of Avian Influenza virus via tangential flow ultra-filtration and whole segment amplification in California wetlands"
#Madeline M. McCuen | Maurice E. Pitesky | Ana Paula da Silva | Rodrigo A. Gallardo | Jeff J. Buler | Sarai Acosta | Alexander Wilcox | Ronald F. Bond | Samuel L. DÃ­az-MuÃ±oz

################ Avian Influenza Viruses Environment ################
#### 1. Data Sources and Preparing Data
#### 2. Analysis of Collected Samples
#### 3. Analysis of Sequencing Reads and FluDB Database Metadata 

#THIS CODE NEEDS FOLOWING FILES: 
# data/aiv_summer_2021_swab_demux.csv,
# data/aiv_summer_2021_swab_amott_edits.csv,
# demultiplexing_by_sample.txt - This file generated by script minion_demultiplexing_flu_assignment.sh
# avian_blast_matches.txt - This file generated by script minion_demultiplexing_flu_assignment.sh
# Individual sample *.out and *.tab files generated by script minion_demultiplexing_flu_assignment.sh

#Project Description
#Analysis of MinION sequence data from water and sediment samples for avian influenza detection in California wetlands
#Code for "Linking remote sensing for targeted surveillance of Avian Influenza virus via tangential flow ultra-filtration and whole segment amplification in California wetlands"
#Collaboration between Diaz-Munoz Lab and Madeline McCuen, Maurice Pitesky (PI), UC Davis

#Load libraries
library(readr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(ggthemes)
library(gridExtra)
library(reshape2)

#### 1. Data Sources and Preparing Data   ####

#Received a spreadsheet from Madeline McCuen via email on September 28, 2018 at 4:59pm
# entitled "AIV_filtration sample key 9_26_18.xlsx" Saved this file as CSV from Excel to import to R

#setwd('/home/user/Documents/CM_aiv_detection_environment')

#Import data from CSV, requires readr package
aiv_water_summer_2021_demux <- read_csv("data/aiv_water_summer_2021_demux.csv")
aiv_water_summer_2021 <- read_csv("data/aiv_water_summer_2021.csv")

#assign sample name by barcode:
aiv_water_summer_2021_data <- left_join(aiv_water_summer_2021_demux, aiv_water_summer_2021)

#Now adding the number of reads recovered from demultiplexed files. Will add separate columns for number of reads that matched avian influenza genomes
demultiplexing_by_sample <- read.table("demultiplexing_by_sample.txt", quote="\"", comment.char="", col.names = c("reads", "barcode"))

#Clean up samples to make sample label match aiv_filtration
demultiplexing_by_sample$barcode <- gsub(".fast.", "", demultiplexing_by_sample$barcode)

aiv_water_summer_2021_data <- left_join(aiv_water_summer_2021_data, demultiplexing_by_sample)

#Removing NA's: carefully!!
aiv_water_summer_2021_data$reads[is.na(aiv_water_summer_2021_data$reads)] <- 0




#Now adding separate columns for number of reads that matched avian influenza genomes
avian_blast_matches <- read.table("avian_blast_matches.txt", quote="\"", comment.char="", col.names = c("matches", "barcode"))

#Clean up samples to make sample label match aiv_water_summer_2021_data
avian_blast_matches$barcode <- gsub(".out", "", avian_blast_matches$barcode)

#Let's add to aiv_water_summer_2021_data
aiv_water_summer_2021_data <- left_join(aiv_water_summer_2021_data, avian_blast_matches)

#Removing NA's: carefully!!
aiv_water_summer_2021_data$matches[is.na(aiv_water_summer_2021_data$matches)] <- 0


## END BONUS SECTION

#### 3. Analysis of Sequencing Reads and FluDB Database Metadata #### 

##First we need import and clean up data. 
#We'll start with importing information from .tab files, which contain metadata for the sequences in FluDB
file_names <- list.files(".", "*.tab")

metadata_avian <- NULL

for (i in 1:length(file_names)) {
  #import each file and add recursively to a data frame
  results <- read_delim(file_names[i], "|", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
  
  sample <- rep(file_names[i], nrow(results))
  results <- cbind(results, sample)
  
  metadata_avian <- rbind(metadata_avian, results)
}  

colnames(metadata_avian) <- c("gi", "organism", "strain", "segment", "subtype", "host", "barcode")

#Cleanup Data Frame Contents
metadata_avian$gi <- gsub(">*[A-z]*:", "", metadata_avian$gi)
metadata_avian$strain <- gsub("[A-z]*\\s[A-z]*:", "", metadata_avian$strain)
metadata_avian$organism <- gsub("[A-z]*:", "", metadata_avian$organism)
metadata_avian$segment <- gsub("[A-z]*:", "", metadata_avian$segment)
metadata_avian$subtype <- gsub("[A-z]*:", "", metadata_avian$subtype)
metadata_avian$host <- gsub("[A-z]*:", "", metadata_avian$host)

metadata_avian$barcode <- gsub("*.tmp.tab", "", metadata_avian$barcode)


#View(metadata_avian)
#View(right_join(metadata_avian, aiv_filtration))

#leaves samples with no matches at bottom....? 
metadata_avian <- right_join(metadata_avian, aiv_water_summer_2021_data)

#Fix the mixed subtypes category
metadata_avian$subtype <- gsub("Mixed", "mixed", metadata_avian$subtype)

#Make a new data frame excluding positive control samples
metadata_avian_samples <- subset(metadata_avian, sample_label != "pos" & sample_label != "neg")

#Now that we're done with metadata, let's bring in the sequence matching information and pair it with the segment information
file_list <- list.files(".", "*.out")

sequence_match_info <- NULL

for (i in 1:length(file_list)) {
  #import each file and add recursively to a data frame
  results <- read_delim(file_list[i], "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
  #colnames(results) <- c("qid", "match", "percent_id", "alignment_length", "mismatches", "gap_opens", "start_query", "end_query", "start_target", "end_target", "evalue", "bitscore")
  
  sample <- rep(file_list[i], nrow(results))
  results <- cbind(results, sample)
  
  sequence_match_info <- rbind(sequence_match_info, results)
}

nrow(sequence_match_info)
#[1] 18817

colnames(sequence_match_info) <- c("qid", "match", "percent_id", "alignment_length", "mismatches", "gap_opens", "start_query", "end_query", "start_target", "end_target", "evalue", "bitscore", "barcode")

#Clean up sample name
sequence_match_info$barcode <- gsub("*.out", "", sequence_match_info$barcode)

#Extract GB to match
sequence_match_info$match <- gsub("gb:", "", sequence_match_info$match)
sequence_match_info$match <- gsub("\\|[A-z]*:[A-z]*", "", sequence_match_info$match)

#Adjust colnames for join
colnames(sequence_match_info) <- c("qid", "gi", "percent_id", "alignment_length", "mismatches", "gap_opens", "start_query", "end_query", "start_target", "end_target", "evalue", "bitscore", "barcode")

#How many sequences left
nrow(sequence_match_info)
#[1] 176685

#Remove Positive Controls (test)
#View(subset(sequence_match_info, `Sample Label` != "PR8 RNA A" & `Sample Label` != "PR8 RNA B"))

#Already removed positives, but changing name so it matches code below
sequence_match_info_samples <- subset(sequence_match_info, barcode != "barcode96")


##Now we can get down to analyses. #These are reported in manuscripts under Results: "Sequencing Data and AIv Database Match Summary"

#Mean alignment length across all segments
mean(sequence_match_info_samples$alignment_length)
#[1] 524.7938

#Number of segments with alignment length over 2.2kpbs
nrow(subset(sequence_match_info_samples, alignment_length > 2200))
#[1] 0

#Of those, how many are > 2.3kpbs?
nrow(subset(sequence_match_info_samples, alignment_length > 2300))
#[1] 0

#Accuracy?
mean(subset(sequence_match_info_samples, alignment_length > 2300)$percent_id)
#[1] 0

#Mean alignment length
mean(sequence_match_info_samples$alignment_length)
#524.7938
sd(sequence_match_info_samples$alignment_length)
#367.044
length(sequence_match_info_samples$alignment_length)
#[1] 291

#Mean percentage identity
mean(sequence_match_info_samples$percent_id)
#[1] 96.89841
sd(sequence_match_info_samples$percent_id)
#[1] 2.811406
length(sequence_match_info_samples$percent_id)
#[1] 291

#Histogram of PID matches
hist(sequence_match_info_samples$percent_id)

#Now we want to add sequence match metadata, but only to existing records
metadata_avian_distinct <- distinct(metadata_avian, gi, .keep_all = TRUE)

#Get only the info from the IRD database
metadata_avian_distinct <- subset(metadata_avian_distinct, select = c("gi", "organism", "strain", "segment", "subtype", "host"))

#Test Join
#View(inner_join(sequence_match_info_samples, metadata_avian_distinct, by = "gi"))

#Join
sequence_match_info_samples <- inner_join(sequence_match_info_samples, metadata_avian_distinct, by = "gi")

#Test if I affected anything with join
mean(sequence_match_info_samples$alignment_length)
#[1] 524.7938
#Same as above, so looks good

#What is the segment match distribution
#These results are repoted in Table 2 in manuscript and also in text 
table(sequence_match_info_samples$segment)
#1  2  3  4  5  6  7  8 
#8 15 60 14 39  3 77 75

#How many samples have at least 1 M segment match? This is to compare to RT-qPCR results.
table(subset(sequence_match_info_samples, segment == 7, select = barcode))
#barcode13 barcode28 barcode34 barcode36 barcode38 barcode44 barcode47 barcode50 barcode78 
#1         1         1         1         1         1         1        21        49 

nrow(table(subset(sequence_match_info_samples, segment == 7, select = barcode)))
#[1] 9
#So if I only count M segment matches as positives by sequencing, I would have 15 positive samples vs 19 if I count any segment (see code below)
#This result is reported in Results: Whole-segment amplification/sequencing yielded more positive samples than M-segment RT-qPCR

#We count as positive the samples that had at least one read matching avian influenza virus genomes database
table(aiv_water_summer_2021_data[,]$matches > 0)
#FALSE  TRUE 
# 62    34
#Need to subtract positive control from this one!

#Are they largely the same samples?
#barcode04 barcode05 barcode06 barcode09 barcode11 barcode12 barcode16 barcode17 barcode18 barcode22 barcode24 barcode28 barcode29 barcode32 
#1         1         1         1         1         1         1         1         1         1         1         1         1         1 
#barcode34 barcode35 barcode36 barcode37 barcode39 barcode40 barcode42 barcode47 barcode48 barcode51 barcode52 barcode53 barcode57 barcode58 
#1         1         1         1         1         1         1         1         1         1         1         1         1         1 
#barcode61 barcode64 barcode66 barcode69 barcode70 barcode71 barcode73 barcode74 barcode75 barcode76 barcode77 barcode81 barcode84 barcode85 
#1         1         1         1         1         1         1         1         1         1         1         1         1         1 
#barcode88 barcode89 barcode93 barcode94 barcode96 
#1         1         1         1         1 

#Yep! Including all read matches added 4 positives: A5 SW Unfltrd, B2 Fltrd RXD, C1 Fltrd RXD, and C1 SW Unfltrd 

#Is there any evidence of identical or similar sequences across samples? No. See analysis in checking_similar_sequences.sh

#Let's do a quick sanity check that this is all working properly
#One way to check is to look at reads here vs AIV filtration

#How many  matches do I have here compared to the original aiv_filtration dataframe?
sequence_check <- group_by(sequence_match_info_samples, barcode) %>%
  summarise(
    count = n(),
  )
#aiv_filtration_check  <- subset(aiv_water_summer_2021_data, filtration != "NA" & matches > 0, select = c("Sample Label", "avian_read_matches"))
aiv_water_summer_2021_data_check  <- subset(aiv_water_summer_2021_data, matches > 0, select = c("barcode", "matches"))

#Join
check <- inner_join(aiv_water_summer_2021_data_check, sequence_check)
which(check$matches != check$matches)
#integer(0)
#They're the same, we're good

#Check out distribution of subtypes
sequence_match_info_samples_subtypes <- subset(sequence_match_info_samples, segment == 4 | segment == 6)

#Filter out short matches
sequence_match_info_samples_subtypes_over500 <- subset(sequence_match_info_samples_subtypes, alignment_length > 500)

#Overall subtype distribution Figure 7 in the text
figure7 <- ggplot(sequence_match_info_samples_subtypes, aes(x = subtype, fill = segment)) + geom_histogram(stat = "count") + scale_y_log10() + coord_flip() 
figure7
#ggsave("figure7.pdf", figure7)

#Overall subtype distribution by location
ggplot(sequence_match_info_samples_subtypes, aes(x = subtype, fill = segment)) + geom_histogram(stat = "count") + scale_y_log10() + coord_flip() + facet_wrap(~ location) 


#Sumary stats
group_by(sequence_match_info_samples_subtypes, segment, subtype) %>%
  summarise(
    count = n(),
    mean_alignment = mean(alignment_length)
  )
#  segment subtype count mean_alignment
#<chr>   <chr>   <int>          <dbl>
#1 4       H7N9       14            29 
#2 6       H1N1        3           547.

#Now let's look at hosts
#Let's add location
#location <- NULL
#location[grep("^A", sequence_match_info_samples$`Sample Label`)] <- "A. Butte county wetland"
#location[grep("^B", sequence_match_info_samples$`Sample Label`)] <- "B. Yolo bypass wildlife area"
#location[grep("^C", sequence_match_info_samples$`Sample Label`)] <- "C. Yolo bypass wildlife area"

sequence_match_info_samples_subtypes <- left_join(sequence_match_info_samples_subtypes, aiv_water_summer_2021_data, by='barcode')
sequence_match_info_samples <- left_join(sequence_match_info_samples, aiv_water_summer_2021_data, by='barcode')



#Let's clean up the repeat names due to minor mispellings
table(sequence_match_info_samples$host)

sequence_match_info_samples$host <- gsub("Blue Winged Teal", "Blue-Winged Teal", sequence_match_info_samples$host)
sequence_match_info_samples$host <- gsub("American Green-Winged Teal", "Green-Winged Teal", sequence_match_info_samples$host)
sequence_match_info_samples$host <- gsub("^Pintail$", "Northern Pintail", sequence_match_info_samples$host)

#Test
#View(cbind(sequence_match_info_samples, location))

#sequence_match_info_samples <- cbind(sequence_match_info_samples, location)

group_by(sequence_match_info_samples, segment) %>%
  summarise(
    count = n(),
    mean = mean(percent_id, na.rm = TRUE),
    sd = sd(percent_id, na.rm = TRUE)
  )
# A tibble: 8 Ã 4
#segment  count  mean    sd
#<chr>    <int> <dbl> <dbl>
#  1 1        1840  94.6  3.01
#2 2         655  95.1  3.21
#3 3        3755  95.6  2.96
#4 4        1149  94.4  2.82
#5 5       11803  94.9  3.07
#6 6        4324  94.5  2.73
#7 7       62885  95.3  2.74
#8 8       90274  95.4  2.63

group_by(sequence_match_info_samples, segment) %>%
  summarise(
    count = n(),
    mean = mean(alignment_length, na.rm = TRUE),
    sd = sd(alignment_length, na.rm = TRUE)
  )
# # A tibble: 8 × 4
#segment count  mean    sd
#<chr>   <int> <dbl> <dbl>
#1 1           8  96.1  2.09
#2 2          15  95.3  2.01
#3 3          60  95.1  3.82
#4 4          14  99.6  1.08
#5 5          39  97.2  1.96
#6 6           3  97.8  1.10
#7 7          77  97.4  2.68
#8 8          75  97.5  1.85

#Now look at hosts of the sequences matched in the database
host_counts_sequence_match <- subset(sequence_match_info_samples, alignment_length > 500) %>%
  group_by(host) %>%
  summarise(n = n())

#Hosts overall, ordered. This is main panel in Figure 8 in the text
figure8 <- ggplot(host_counts_sequence_match, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip()
figure8
#ggsave("figure8.pdf", figure8)


#Ok. Now Plot the Hosts, but by site
#Make a data frame by site ordered
host_counts_site_sequence_match <-subset(sequence_match_info_samples, alignment_length > 500) %>%
  group_by(host, `Wildlife Management Unit`) %>%
  summarise(n = n())

#Plot by site ordered
ggplot(host_counts_site_sequence_match, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip() + facet_wrap(~ `Wildlife Management Unit`, scales = "free_x")

#For Brock Presentation: Plot by sample, subdivided by site
ggplot(host_counts_site_sequence_match, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip() + facet_wrap(~ `Wildlife Management Unit`, scales = "free_x")

#By Site ordered, exclude hosts that are only represented by 1 or 2 matches
figure8_inset <- ggplot(subset(host_counts_site_sequence_match, n > 2), aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip() + facet_wrap(~ `Wildlife Management Unit`, scales = "free_x")
figure8_inset
#ggsave("figure8_inset.pdf", figure8_inset)



#Excluding hosts predicted by just a few reads
ggplot(subset(host_counts_site_sequence_match, n > 2), aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip()









## These summary statistics are found in paper under Results: "California Wetlands Harbor Avian Viruses from Multiple Potential Host Origins and Subtypes"  
#Total host matches that have 
sum(host_counts_sequence_match$n)
#[1] 137

#How many hosts identified? Remember this dataframe is grouped by hosts so, rows == # of hosts
nrow(host_counts_sequence_match)
#[1] 7

#Sort hosts and get the percentage of total matches by the top 5 hosts
(sort(host_counts_sequence_match$n, decreasing = TRUE)[1:5] / sum(host_counts_sequence_match$n))*100
#[1]  36.496350 23.357664 20.437956 17.518248  0.729927

#Top 5 summed percentages
sum(sort(host_counts_sequence_match$n, decreasing = TRUE)[1:5] / sum(host_counts_sequence_match$n))*100
#[1] 98.54015





#courtney added plots



ggplot(data=sequence_match_info_samples, aes(sample_label, segment))+
  geom_point()

#Modification of above to show number of segments in samples
ggplot(data=sequence_match_info_samples, aes(sample_label, as.factor(segment), fill=segment)) +
  geom_bar(position = "fill",stat = "identity") + coord_flip()

ggplot(data=sequence_match_info_samples, aes(segment, fill=segment)) +
  geom_bar(position = "fill") + facet_wrap(~ sample_label, scales = "free_y")
number_segments_sample <- ggplot(data=sequence_match_info_samples, aes(segment, fill=segment)) + geom_bar(position = "fill") + facet_wrap(~ sample_label, scales = "free_y")
ggsave("water_figures/number_segments_sample.pdf", number_segments_sample)


ggplot(data=sequence_match_info_samples, aes(`Wildlife Management Unit`, subtype))+
  geom_col()

ggplot(data=sequence_match_info_samples, aes(fill=subtype, x=`Wildlife Management Unit`, y=subtype))+
  geom_point()

#### 4. Prevalence and BLAST Matching Stats #### 

#Number of reads per sample, colored by species
ggplot(data=aiv_water_summer_2021_data, aes(x=reorder(barcode, reads), y=reads)) + geom_col() + coord_flip()
read_prevalence <- ggplot(data=aiv_water_summer_2021_data, aes(x=reorder(barcode, reads), y=reads)) + geom_col() + coord_flip()
ggsave("water_figures/read_prevalence.pdf", read_prevalence)

#Number of reads matchig the flu database per sample
ggplot(data=subset(aiv_water_summer_2021_data, sample_label != "pos"), aes(x=reorder(sample_label, matches), y=matches)) + geom_col() + coord_flip()
match_prevalence <- ggplot(data=subset(aiv_water_summer_2021_data, sample_label != "pos"), aes(x=reorder(sample_label, matches), y=matches)) + geom_col() + coord_flip()
ggsave("water_figures/match_prevalence.pdf", match_prevalence)

#Prevalence per site
ggplot(data=subset(aiv_water_summer_2021_data, `Wildlife Management Unit` != "NA"), aes(fill=sample_label, x= `Wildlife Management Unit`, y=matches)) + geom_col() + theme(legend.position = "none")
#Summary_Stats
#summarise()

ggplot(data=aiv_water_summer_2021_data, aes(x=reorder(species, matches), y=matches)) + geom_col() + coord_flip() + scale_y_log10()


#Plots for Brock Presentation 

#Host by sample
hosts_by_sample <- group_by(sequence_match_info_samples, sample_label, strain, host, `Wildlife Management Unit`) %>%
  summarise(
    count = n(),
    mean_align = mean(alignment_length, na.rm = TRUE),
    sd_align = sd(alignment_length, na.rm = TRUE),
    mean_id = mean(percent_id, na.rm = TRUE),
    sd_id = sd(percent_id, na.rm = TRUE)
  )

View(hosts_by_sample)

#This tells me the top host predicted according to the reads in that sample.
hosts_by_sample <- hosts_by_sample %>% group_by(sample_label) %>% slice_max(count,n = 1, with_ties = FALSE)

#Plot by site
hosts_by_sample_location <- hosts_by_sample %>%
  group_by(host, `Wildlife Management Unit`) %>%
  summarise(n = n())

#Plot
ggplot(hosts_by_sample_location, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Closest Predicted Host by FluDB Best Match") + coord_flip() + facet_wrap(~factor(`Wildlife Management Unit`))

#Plot overall
hosts_by_sample_total <- hosts_by_sample %>%
  group_by(host) %>%
  summarise(n = n())

#Plot predicted 
ggplot(hosts_by_sample_location, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Closest Predicted Host by FluDB Best Match") + coord_flip()
predicted_hosts_overall <- ggplot(hosts_by_sample_location, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Closest Predicted Host by FluDB Best Match") + coord_flip()
ggsave("water_figures/predicted_hosts_overall.pdf", predicted_hosts_overall)

#Subtype by sample
subtype_by_sample <- group_by(subset(sequence_match_info_samples, segment == "4" | segment == "6"), sample_label, segment, subtype, host, `Wildlife Management Unit`) %>%
  summarise(
    count = n(),
    mean_align = mean(alignment_length, na.rm = TRUE),
    sd_align = sd(alignment_length, na.rm = TRUE),
    mean_id = mean(percent_id, na.rm = TRUE),
    sd_id = sd(percent_id, na.rm = TRUE)
  )

View(subtype_by_sample)

#This tells me the top host predicted according to the reads in that sample.
subtype_by_sample <- subtype_by_sample %>% group_by(sample_label, segment) %>% slice_max(count,n = 1, with_ties = FALSE)

#Now split the subtype (ugly but works for now)
subtype_by_sample <- separate(subtype_by_sample, subtype, c("subH", "HA", "subN", "NA"), sep = "(?=[A-Za-z])(?<=[0-9])|(?=[0-9])(?<=[A-Za-z])", remove = F)

subtype_by_sample <- select(subtype_by_sample, !(c("subH", "subN")))

#Now need to reconstruct subtype from the match in each sample
subset(subtype_by_sample, segment == "4")$HA

#Get HA's
h <- subtype_by_sample %>% filter(segment == "4") %>% select(HA)
subset(h, select == "segment")
#Get NA's
n <- subtype_by_sample %>% filter(segment == "6") %>% select(`NA`)

subtypes_only <- subtypes_only[c(1,3,5)]

#Make a true subtype column
subtypes_only <- unite(subtypes_only, correct_subtype, c("HA", `NA`), sep = "_")

#Clean up with Grep
subtypes_only$correct_subtype <- gsub("^NA_", "H?N", subtypes_only$correct_subtype)
subtypes_only$correct_subtype <- gsub("_NA$", "N?", subtypes_only$correct_subtype)
#Add the N
subtypes_only$correct_subtype <- gsub("_", "N", subtypes_only$correct_subtype)

#Now add an H in front of all
subtypes_only$correct_subtype <- paste("H", subtypes_only$correct_subtype, sep = "")
#This is so hacky, it's delicious
subtypes_only$correct_subtype <- gsub("^HH", "H", subtypes_only$correct_subtype)

#Now merge to get sample info on the data frame 
subtypes_only <- left_join(subtypes_only, aiv_water_summer_2021_data)

#Calculate number of subtypes
subtypes_by_sample_total <- subtypes_only %>%
  group_by(correct_subtype, location) %>%
  summarise(n = n())

#Now plot!!
#Overall, coloring by species
ggplot(subtypes_by_sample_total, aes(x = correct_subtype, y = n, fill=species)) + geom_bar(aes(reorder(correct_subtype, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Predicted Subtype by FluDB Best Match") + coord_flip()

#Breakdown by location
ggplot(subtypes_by_sample_total, aes(x = correct_subtype, y = n, fill=species)) + geom_bar(aes(reorder(correct_subtype, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Predicted Subtype by FluDB Best Match") + coord_flip() + facet_wrap(~factor(location, levels=c("SAC_P4", "SAC_10.2", "DEL_T20.2")))

#Prevalence overall by location
sample_total <- aiv_water_summer_2021_data %>%
  group_by(`Wildlife Management Unit`) %>%
  summarise(n = n())

sample_total <- subset(sample_total, !is.na(`Wildlife Management Unit`))
colnames(sample_total) <- c("location", "total_samples") 

match_totals <- sequence_match_info_samples %>%
  group_by(`Wildlife Management Unit`, sample_label) %>%
  summarise(n = n())

colnames(match_totals) <- c("location", "sample_label", "n")

match_totals <- match_totals[1:2] %>% 
  group_by(location) %>%
  summarise(n = n())

prevalence_per_sample <- right_join(sample_total, match_totals)

#Nice plot of overall prevalence
ggplot(prevalence_per_sample, aes(x = location, y = n)) + geom_bar(aes(reorder(location, n), n), stat = "identity") + geom_errorbar(aes(y = total_samples, ymax = total_samples, ymin = total_samples)) + geom_text(aes(label = round(n/total_samples*100, digits = 2)), parse = TRUE, position = position_stack(0.95), vjust = 1, colour = "white") + ylab("Number of Samples") + xlab("Location")
overall_prevalence_location <- ggplot(prevalence_per_sample, aes(x = location, y = n)) + geom_bar(aes(reorder(location, n), n), stat = "identity") + geom_errorbar(aes(y = total_samples, ymax = total_samples, ymin = total_samples)) + geom_text(aes(label = round(n/total_samples*100, digits = 2)), parse = TRUE, position = position_stack(0.95), vjust = 1, colour = "white") + ylab("Number of Samples") + xlab("Location")
ggsave("water_figures/overall_prevalence_location.pdf", overall_prevalence_location)


#Prevalence overall by low/hi
sample_total_use_level <- aiv_water_summer_2021_data %>%
  group_by(`Use Level`) %>%
  summarise(n = n())

sample_total_use_level <- subset(sample_total_use_level, !is.na(`Use Level`))
colnames(sample_total_use_level) <- c("Use Level", "total_samples") 

match_totals_use_level <- sequence_match_info_samples %>%
  group_by(`Use Level`, sample_label) %>%
  summarise(n = n())

match_totals_use_level <- match_totals_use_level[1:2] %>% 
  group_by(`Use Level`) %>%
  summarise(n = n())

prevalence_use_level <- right_join(sample_total_use_level, match_totals_use_level)

#Can do a quick prop test here to test the differences
prop.test(c(20, 13), c(49, 45))
#2-sample test for equality of proportions with continuity correction

#data:  c(20, 13) out of c(49, 45)
#X-squared = 0.98806, df = 1, p-value = 0.3202
#alternative hypothesis: two.sided
#95 percent confidence interval:
#  -0.09302496  0.33157372
#sample estimates:
#  prop 1    prop 2 
#0.4081633 0.2888889 

#Nice plot of overall prevalence by use level
ggplot(prevalence_use_level, aes(x = `Use Level`, y = n)) + geom_bar(aes(reorder(`Use Level`, n), n), stat = "identity") + geom_errorbar(aes(y = total_samples, ymax = total_samples, ymin = total_samples)) + geom_text(aes(label = round(n/total_samples*100, digits = 2)), parse = TRUE, position = position_stack(0.95), vjust = 1, colour = "white") + ylab("Number of Samples") + xlab("Use Level")
overall_prevalence_use_level <- ggplot(prevalence_use_level, aes(x = `Use Level`, y = n)) + geom_bar(aes(reorder(`Use Level`, n), n), stat = "identity") + geom_errorbar(aes(y = total_samples, ymax = total_samples, ymin = total_samples)) + geom_text(aes(label = round(n/total_samples*100, digits = 2)), parse = TRUE, position = position_stack(0.95), vjust = 1, colour = "white") + ylab("Number of Samples") + xlab("Use Level")
ggsave("water_figures/overall_prevalence_use_level.pdf", overall_prevalence_use_level)


#Prevalence overall by filtered
sample_total_filtered <- aiv_water_summer_2021_data %>%
  group_by(`Filtered?`) %>%
  summarise(n = n())

sample_total_filtered <- subset(sample_total_filtered, !is.na(`Filtered?`))
colnames(sample_total_filtered) <- c("Filtered?", "total_samples") 

match_totals_filtered <- sequence_match_info_samples %>%
  group_by(`Filtered?`, sample_label) %>%
  summarise(n = n())

match_totals_filtered <- match_totals_filtered[1:2] %>% 
  group_by(`Filtered?`) %>%
  summarise(n = n())

prevalence_filtered <- right_join(sample_total_filtered, match_totals_filtered)

#Can do a quick prop test here to test the differences
prop.test(c(3, 30), c(5, 89))
#	2-sample test for equality of proportions with continuity correction

#data:  c(3, 30) out of c(5, 89)
#X-squared = 0.51419, df = 1, p-value = 0.4733
#alternative hypothesis: two.sided
#95 percent confidence interval:
#  -0.2831906  0.8090333
#sample estimates:
#  prop 1    prop 2 
#0.6000000 0.3370787 


#Nice plot of overall prevalence by use level
ggplot(prevalence_filtered, aes(x = `Filtered?`, y = n)) + geom_bar(aes(reorder(`Filtered?`, n), n), stat = "identity") + geom_errorbar(aes(y = total_samples, ymax = total_samples, ymin = total_samples)) + geom_text(aes(label = round(n/total_samples*100, digits = 2)), parse = TRUE, position = position_stack(0.95), vjust = 1, colour = "white") + ylab("Number of Samples") + xlab("Use Level")
overall_prevalence_filtered <- ggplot(prevalence_filtered, aes(x = `Filtered?`, y = n)) + geom_bar(aes(reorder(`Filtered?`, n), n), stat = "identity") + geom_errorbar(aes(y = total_samples, ymax = total_samples, ymin = total_samples)) + geom_text(aes(label = round(n/total_samples*100, digits = 2)), parse = TRUE, position = position_stack(0.95), vjust = 1, colour = "white") + ylab("Number of Samples") + xlab("Use Level")
ggsave("water_figures/overall_prevalence_filtered.pdf", overall_prevalence_filtered)

