# Script: aiv_detection_environment_analysis.R
# This file is an R script that couples sequencing information with sample information to arive at the main conclusions in the manuscript
# NOTE: This file depends on minion_demultiplexing_flu_assignment.sh. Run that script first!

#This script is part of the following manuscript:
#Analysis of MinION sequence data from water and sediment samples for avian influenza detection in California wetlands
#This github repository includes code (and links to data) from the manuscript:
#"Linking remote sensing for targeted surveillance of Avian Influenza virus via tangential flow ultra-filtration and whole segment amplification in California wetlands"
#Madeline M. McCuen | Maurice E. Pitesky | Ana Paula da Silva | Rodrigo A. Gallardo | Jeff J. Buler | Sarai Acosta | Alexander Wilcox | Ronald F. Bond | Samuel L. DÃ­az-MuÃ±oz

################ Avian Influenza Viruses Environment ################
#### 1. Data Sources and Preparing Data
#### 2. Analysis of Collected Samples
#### 3. Analysis of Sequencing Reads and FluDB Database Metadata 

#THIS CODE NEEDS FOLOWING FILES: 
# data/aiv_summer_2021_swab_demux.csv,
# data/aiv_summer_2021_swab_amott_edits.csv,
# demultiplexing_by_sample.txt - This file generated by script minion_demultiplexing_flu_assignment.sh
# avian_blast_matches.txt - This file generated by script minion_demultiplexing_flu_assignment.sh
# Individual sample *.out and *.tab files generated by script minion_demultiplexing_flu_assignment.sh

#Project Description
#Analysis of MinION sequence data from water and sediment samples for avian influenza detection in California wetlands
#Code for "Linking remote sensing for targeted surveillance of Avian Influenza virus via tangential flow ultra-filtration and whole segment amplification in California wetlands"
#Collaboration between Diaz-Munoz Lab and Madeline McCuen, Maurice Pitesky (PI), UC Davis

#Load libraries
library(readr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(ggthemes)
library(gridExtra)
library(reshape2)

#### 1. Data Sources and Preparing Data   ####

#Received a spreadsheet from Madeline McCuen via email on September 28, 2018 at 4:59pm
# entitled "AIV_filtration sample key 9_26_18.xlsx" Saved this file as CSV from Excel to import to R

#setwd('/home/user/Documents/CM_aiv_detection_environment')

#Import data from CSV, requires readr package
s21_swab_demux <- read_csv("data/aiv_summer_2021_swab_demux.csv")
s21_swab_data <- read_csv("data/aiv_summer_2021_swab_amott_edits.csv")

#assign sample name by barcode:
s21_swab_data <- left_join(s21_swab_demux, s21_swab_data)


#Now adding the number of reads recovered from demultiplexed files. Will add separate columns for number of reads that matched avian influenza genomes
demultiplexing_by_sample <- read.table("demultiplexing_by_sample.txt", quote="\"", comment.char="", col.names = c("reads", "barcode"))

#Clean up samples to make sample label match aiv_filtration
demultiplexing_by_sample$barcode <- gsub(".fast.", "", demultiplexing_by_sample$barcode)

s21_swab_data <- left_join(s21_swab_data, demultiplexing_by_sample)

#Removing NA's: carefully!!
s21_swab_data$reads[is.na(s21_swab_data$reads)] <- 0




#Now adding separate columns for number of reads that matched avian influenza genomes
avian_blast_matches <- read.table("avian_blast_matches.txt", quote="\"", comment.char="", col.names = c("matches", "barcode"))

#Clean up samples to make sample label match s21_swab_data
avian_blast_matches$barcode <- gsub(".out", "", avian_blast_matches$barcode)

#Let's add to s21_swab_data
s21_swab_data <- left_join(s21_swab_data, avian_blast_matches)

#Removing NA's: carefully!!
s21_swab_data$matches[is.na(s21_swab_data$matches)] <- 0


## END BONUS SECTION

#### 3. Analysis of Sequencing Reads and FluDB Database Metadata #### 

##First we need import and clean up data. 
#We'll start with importing information from .tab files, which contain metadata for the sequences in FluDB
file_names <- list.files(".", "*.tab")

metadata_avian <- NULL

for (i in 1:length(file_names)) {
  #import each file and add recursively to a data frame
  results <- read_delim(file_names[i], "|", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
  
  sample <- rep(file_names[i], nrow(results))
  results <- cbind(results, sample)
  
  metadata_avian <- rbind(metadata_avian, results)
}  

colnames(metadata_avian) <- c("gi", "organism", "strain", "segment", "subtype", "host", "barcode")

#Cleanup Data Frame Contents
metadata_avian$gi <- gsub(">*[A-z]*:", "", metadata_avian$gi)
metadata_avian$strain <- gsub("[A-z]*\\s[A-z]*:", "", metadata_avian$strain)
metadata_avian$organism <- gsub("[A-z]*:", "", metadata_avian$organism)
metadata_avian$segment <- gsub("[A-z]*:", "", metadata_avian$segment)
metadata_avian$subtype <- gsub("[A-z]*:", "", metadata_avian$subtype)
metadata_avian$host <- gsub("[A-z]*:", "", metadata_avian$host)

metadata_avian$barcode <- gsub("*.tmp.tab", "", metadata_avian$barcode)


#View(metadata_avian)
#View(right_join(metadata_avian, aiv_filtration))

#leaves samples with no matches at bottom....? 
metadata_avian <- right_join(metadata_avian, s21_swab_data)

#Fix the mixed subtypes category
metadata_avian$subtype <- gsub("Mixed", "mixed", metadata_avian$subtype)

#Make a new data frame excluding positive control samples
metadata_avian_samples <- subset(metadata_avian, sample_label != "pos" & sample_label != "neg")

#Now that we're done with metadata, let's bring in the sequence matching information and pair it with the segment information
file_list <- list.files(".", "*.out")

sequence_match_info <- NULL

for (i in 1:length(file_list)) {
  #import each file and add recursively to a data frame
  results <- read_delim(file_list[i], "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
  #colnames(results) <- c("qid", "match", "percent_id", "alignment_length", "mismatches", "gap_opens", "start_query", "end_query", "start_target", "end_target", "evalue", "bitscore")
  
  sample <- rep(file_list[i], nrow(results))
  results <- cbind(results, sample)
  
  sequence_match_info <- rbind(sequence_match_info, results)
}

nrow(sequence_match_info)
#[1] 176687

colnames(sequence_match_info) <- c("qid", "match", "percent_id", "alignment_length", "mismatches", "gap_opens", "start_query", "end_query", "start_target", "end_target", "evalue", "bitscore", "barcode")

#Clean up sample name
sequence_match_info$barcode <- gsub("*.out", "", sequence_match_info$barcode)

#Extract GB to match
sequence_match_info$match <- gsub("gb:", "", sequence_match_info$match)
sequence_match_info$match <- gsub("\\|[A-z]*:[A-z]*", "", sequence_match_info$match)

#Adjust colnames for join
colnames(sequence_match_info) <- c("qid", "gi", "percent_id", "alignment_length", "mismatches", "gap_opens", "start_query", "end_query", "start_target", "end_target", "evalue", "bitscore", "barcode")

#How many sequences left if I remove the positive control
nrow(subset(sequence_match_info, barcode != "barcode81"))
#[1] 176685

#Remove Positive Controls (test)
#View(subset(sequence_match_info, `Sample Label` != "PR8 RNA A" & `Sample Label` != "PR8 RNA B"))

#Subset to remove positive controls (barcode 81 is the pos)
sequence_match_info_samples <- subset(sequence_match_info, barcode != "barcode81")


##Now we can get down to analyses. #These are reported in manuscripts under Results: "Sequencing Data and AIv Database Match Summary"

#Mean alignment length across all segments
mean(sequence_match_info_samples$alignment_length)
#[1] 915.7056

#Number of segments with alignment length over 2.2kpbs
nrow(subset(sequence_match_info_samples, alignment_length > 2200))
#[1] 1473

#Of those, how many are > 2.3kpbs?
nrow(subset(sequence_match_info_samples, alignment_length > 2300))
#[1] 973

#Accuracy?
mean(subset(sequence_match_info_samples, alignment_length > 2300)$percent_id)
#[1] 94.12474

#Mean alignment length
mean(sequence_match_info_samples$alignment_length)
#915.7056
sd(sequence_match_info_samples$alignment_length)
#288.0235
length(sequence_match_info_samples$alignment_length)
#[1] 176685

#Mean percentage identity
mean(sequence_match_info_samples$percent_id)
#[1] 95.30452
sd(sequence_match_info_samples$percent_id)
#[1] 2.724575
length(sequence_match_info_samples$percent_id)
#[1] 176685

#Histogram of PID matches
hist(sequence_match_info_samples$percent_id)

#Now we want to add sequence match metadata, but only to existing records
metadata_avian_distinct <- distinct(metadata_avian, gi, .keep_all = TRUE)

#Get only the info from the IRD database
metadata_avian_distinct <- subset(metadata_avian_distinct, select = c("gi", "organism", "strain", "segment", "subtype", "host"))

#Test Join
#View(inner_join(sequence_match_info_samples, metadata_avian_distinct, by = "gi"))

#Join
sequence_match_info_samples <- inner_join(sequence_match_info_samples, metadata_avian_distinct, by = "gi")

#Test if I affected anything with join
mean(sequence_match_info_samples$alignment_length)
#[1] 915.7056
#Same as above, so looks good

#What is the segment match distribution
#These results are repoted in Table 2 in manuscript and also in text 
table(sequence_match_info_samples$segment)
#1      2      3      4      5      6      7      8 
#1840   655  3755  1149   11803   4324  62885  90274

#How many samples have at least 1 M segment match? This is to compare to RT-qPCR results.
table(subset(sequence_match_info_samples, segment == 7, select = barcode))
#barcode04 barcode05 barcode06 barcode11 barcode12 barcode16 barcode22 barcode24 barcode28 barcode29 barcode35 
#4         4         2      2899       299         3        13      3702         6     12940        17 
#barcode36 barcode37 barcode39 barcode40 barcode42 barcode47 barcode48 barcode52 barcode57 barcode58 barcode61 
#2      1533         5        13        11         3     11915        34         1         3        24 
#barcode64 barcode66 barcode70 barcode73 barcode74 barcode75 barcode76 barcode77 barcode84 barcode85 barcode88 
#1         4       174       219         9        20        42         6         4        17      9623 
#barcode89 barcode93 barcode94 barcode96 
#3         1     19326         3 

nrow(table(subset(sequence_match_info_samples, segment == 7, select = barcode)))
#[1] 37
#So if I only count M segment matches as positives by sequencing, I would have 15 positive samples vs 19 if I count any segment (see code below)
#This result is reported in Results: Whole-segment amplification/sequencing yielded more positive samples than M-segment RT-qPCR

#We count as positive the samples that had at least one read matching avian influenza virus genomes database
table(s21_swab_data[,]$matches > 0)
#FALSE  TRUE 
#49    47 

#Are they largely the same samples?
#barcode04 barcode05 barcode06 barcode09 barcode11 barcode12 barcode16 barcode17 barcode18 barcode22 barcode24 barcode28 barcode29 barcode32 
#1         1         1         1         1         1         1         1         1         1         1         1         1         1 
#barcode34 barcode35 barcode36 barcode37 barcode39 barcode40 barcode42 barcode47 barcode48 barcode51 barcode52 barcode53 barcode57 barcode58 
#1         1         1         1         1         1         1         1         1         1         1         1         1         1 
#barcode61 barcode64 barcode66 barcode69 barcode70 barcode71 barcode73 barcode74 barcode75 barcode76 barcode77 barcode81 barcode84 barcode85 
#1         1         1         1         1         1         1         1         1         1         1         1         1         1 
#barcode88 barcode89 barcode93 barcode94 barcode96 
#1         1         1         1         1 

#Yep! Including all read matches added 4 positives: A5 SW Unfltrd, B2 Fltrd RXD, C1 Fltrd RXD, and C1 SW Unfltrd 

#Is there any evidence of identical or similar sequences across samples? No. See analysis in checking_similar_sequences.sh

#Let's do a quick sanity check that this is all working properly
#One way to check is to look at reads here vs AIV filtration

#How many  matches do I have here compared to the original aiv_filtration dataframe?
sequence_check <- group_by(sequence_match_info_samples, barcode) %>%
  summarise(
    count = n(),
  )
#aiv_filtration_check  <- subset(s21_swab_data, filtration != "NA" & matches > 0, select = c("Sample Label", "avian_read_matches"))
s21_swab_data_check  <- subset(s21_swab_data, matches > 0, select = c("barcode", "matches"))

#Join
check <- inner_join(s21_swab_data_check, sequence_check)
which(check$matches != check$matches)
#integer(0)
#They're the same, we're good

#Check out distribution of subtypes
sequence_match_info_samples_subtypes <- subset(sequence_match_info_samples, segment == 4 | segment == 6)

#Filter out short matches
sequence_match_info_samples_subtypes_over500 <- subset(sequence_match_info_samples_subtypes, alignment_length > 500)

#Overall subtype distribution Figure 7 in the text
figure7 <- ggplot(sequence_match_info_samples_subtypes_over500, aes(x = subtype, fill = segment)) + geom_histogram(stat = "count") + scale_y_log10() + coord_flip() 
figure7
#ggsave("figure7.pdf", figure7)

#Overall subtype distribution by location
ggplot(sequence_match_info_samples_subtypes_over500, aes(x = subtype, fill = segment)) + geom_histogram(stat = "count") + scale_y_log10() + coord_flip() + facet_wrap(~ location) 


#Sumary stats
group_by(sequence_match_info_samples_subtypes, segment, subtype) %>%
  summarise(
    count = n(),
    mean_alignment = mean(alignment_length)
  )
# A tibble: 37 x 4
# Groups:   segment [2]
#segment subtype count mean_alignment
#<chr>   <chr>   <int>          <dbl>
#1 4       H10N1       1          1749 
#2 4       H10N2       1          1713 
#3 4       H10N3     980          1660.
#4 4       H10N4       1          1727 
#5 4       H10N5       4          1724.
#6 4       H10N6       1          1706 
#7 4       H10N7      39          1632.
#8 4       H10N8       5          1700.
#9 4       H10N9       2          1732 
#10 4       H2N3       43          1658.
# … with 27 more rows

#Now let's look at hosts
#Let's add location
#location <- NULL
#location[grep("^A", sequence_match_info_samples$`Sample Label`)] <- "A. Butte county wetland"
#location[grep("^B", sequence_match_info_samples$`Sample Label`)] <- "B. Yolo bypass wildlife area"
#location[grep("^C", sequence_match_info_samples$`Sample Label`)] <- "C. Yolo bypass wildlife area"

sequence_match_info_samples_subtypes <- left_join(sequence_match_info_samples_subtypes, s21_swab_data, by='barcode')
sequence_match_info_samples <- left_join(sequence_match_info_samples, s21_swab_data, by='barcode')



#Let's clean up the repeat names due to minor mispellings
table(sequence_match_info_samples$host)

sequence_match_info_samples$host <- gsub("Blue Winged Teal", "Blue-Winged Teal", sequence_match_info_samples$host)
sequence_match_info_samples$host <- gsub("American Green-Winged Teal", "Green-Winged Teal", sequence_match_info_samples$host)
sequence_match_info_samples$host <- gsub("^Pintail$", "Northern Pintail", sequence_match_info_samples$host)

#Test
#View(cbind(sequence_match_info_samples, location))

#sequence_match_info_samples <- cbind(sequence_match_info_samples, location)

group_by(sequence_match_info_samples, segment) %>%
  summarise(
    count = n(),
    mean = mean(percent_id, na.rm = TRUE),
    sd = sd(percent_id, na.rm = TRUE)
  )
# A tibble: 8 Ã 4
#segment  count  mean    sd
#<chr>    <int> <dbl> <dbl>
#  1 1        1840  94.6  3.01
#2 2         655  95.1  3.21
#3 3        3755  95.6  2.96
#4 4        1149  94.4  2.82
#5 5       11803  94.9  3.07
#6 6        4324  94.5  2.73
#7 7       62885  95.3  2.74
#8 8       90274  95.4  2.63

group_by(sequence_match_info_samples, segment) %>%
  summarise(
    count = n(),
    mean = mean(alignment_length, na.rm = TRUE),
    sd = sd(alignment_length, na.rm = TRUE)
  )
# A tibble: 8 Ã 4
#segment  count  mean     sd
#<chr>    <int> <dbl>  <dbl>
#1 1        1840 1013.  986. 
#2 2         655 1444. 1028. 
#3 3        3755  636.  640. 
#4 4        1149 1467.  537. 
#5 5       11803  590.  599. 
#6 6        4324 1353.  352. 
#7 7       62885  986.  175. 
#8 8       90274  887.   58.1

#Now look at hosts of the sequences matched in the database
host_counts_sequence_match <- subset(sequence_match_info_samples, alignment_length > 500) %>%
  group_by(host) %>%
  summarise(n = n())

#Hosts overall, ordered. This is main panel in Figure 8 in the text
figure8 <- ggplot(host_counts_sequence_match, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip()
figure8
#ggsave("figure8.pdf", figure8)


#Ok. Now Plot the Hosts, but by site
#Make a data frame by site ordered
host_counts_site_sequence_match <-subset(sequence_match_info_samples, alignment_length > 500) %>%
  group_by(host, location) %>%
  summarise(n = n())

#Plot by site ordered
ggplot(host_counts_site_sequence_match, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip() + facet_wrap(~ location, scales = "free_x")

#For Brock Presentation: Plot by sample, subdivided by site
ggplot(host_counts_site_sequence_match, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip() + facet_wrap(~ location, scales = "free_x")

#By Site ordered, exclude hosts that are only represented by 1 or 2 matches
figure8_inset <- ggplot(subset(host_counts_site_sequence_match, n > 2), aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip() + facet_wrap(~ location, scales = "free_x")
figure8_inset
#ggsave("figure8_inset.pdf", figure8_inset)



#Excluding hosts predicted by just a few reads
ggplot(subset(host_counts_site_sequence_match, n > 2), aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip()









## These summary statistics are found in paper under Results: "California Wetlands Harbor Avian Viruses from Multiple Potential Host Origins and Subtypes"  
#Total host matches that have 
sum(host_counts_sequence_match$n)
#[1] 160138

#How many hosts identified? Remember this dataframe is grouped by hosts so, rows == # of hosts
nrow(host_counts_sequence_match)
#[1] 99

#Sort hosts and get the percentage of total matches by the top 5 hosts
(sort(host_counts_sequence_match$n, decreasing = TRUE)[1:5] / sum(host_counts_sequence_match$n))*100
#[1]  41.053966 32.304013 15.910028  2.578401  1.918970

#Top 5 summed percentages
sum(sort(host_counts_sequence_match$n, decreasing = TRUE)[1:5] / sum(host_counts_sequence_match$n))*100
#[1]  93.76538





#courtney added plots



ggplot(data=sequence_match_info_samples, aes(sample_label, segment))+
  geom_point()

#Modification of above to show number of segments in samples
ggplot(data=sequence_match_info_samples, aes(sample_label, as.factor(segment), fill=segment)) +
  geom_bar(position = "fill",stat = "identity") + coord_flip()

ggplot(data=sequence_match_info_samples, aes(segment, fill=segment)) +
  geom_bar(position = "fill") + facet_wrap(~ sample_label, scales = "free_y")

ggplot(data=sequence_match_info_samples, aes(location, subtype))+
  geom_col()

ggplot(data=sequence_match_info_samples, aes(fill=subtype, x=location, y=subtype))+
  geom_point()

#### 4. Prevalence and BLAST Matching Stats #### 

#Number of reads per swab sample, colored by species
ggplot(data=s21_swab_data, aes(x=reorder(barcode, reads), y=reads)) + geom_col() + coord_flip()

#Number of reads matchig the flu database per swab sample
ggplot(data=s21_swab_data, aes(fill=species, x=reorder(sample_label, matches), y=matches)) + scale_y_log10() + geom_col() + coord_flip()

#Prevalence per site
ggplot(data=subset(s21_swab_data, location != "NA"), aes(fill=sample_label, x= location, y=matches)) + geom_col() + theme(legend.position = "none")
#Summary_Stats
#summarise()

ggplot(data=s21_swab_data, aes(x=reorder(species, matches), y=matches)) + geom_col() + coord_flip() + scale_y_log10()


#Plots for Brock Presentation 

#Host by sample
hosts_by_sample <- group_by(sequence_match_info_samples, sample_label, strain, host, species, location) %>%
  summarise(
    count = n(),
    mean_align = mean(alignment_length, na.rm = TRUE),
    sd_align = sd(alignment_length, na.rm = TRUE),
    mean_id = mean(percent_id, na.rm = TRUE),
    sd_id = sd(percent_id, na.rm = TRUE)
  )

View(hosts_by_sample)

#This tells me the top host predicted according to the reads in that sample.
hosts_by_sample <- hosts_by_sample %>% group_by(sample_label) %>% slice_max(count,n = 1, with_ties = FALSE)

#Plot by site
hosts_by_sample_location <- hosts_by_sample %>%
  group_by(host, location) %>%
  summarise(n = n())

#Plot
ggplot(hosts_by_sample_location, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Closest Predicted Host by FluDB Best Match") + coord_flip() + facet_wrap(~factor(location, levels=c("SAC_P4", "SAC_10.2", "DEL_T20.2")))

#Plot overall
hosts_by_sample_total <- hosts_by_sample %>%
  group_by(host, species) %>%
  summarise(n = n())

#Plot predicted 
ggplot(hosts_by_sample_location, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Closest Predicted Host by FluDB Best Match") + coord_flip()

#Plot Actual
ggplot(hosts_by_sample_total, aes(x = species, y = n)) + geom_bar(aes(reorder(species, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Species identity of Swabbed Bird") + coord_flip()



#Subtype by sample
subtype_by_sample <- group_by(subset(sequence_match_info_samples, segment == "4" | segment == "6"), sample_label, segment, subtype, host, species, location) %>%
  summarise(
    count = n(),
    mean_align = mean(alignment_length, na.rm = TRUE),
    sd_align = sd(alignment_length, na.rm = TRUE),
    mean_id = mean(percent_id, na.rm = TRUE),
    sd_id = sd(percent_id, na.rm = TRUE)
  )

View(subtype_by_sample)

#This tells me the top host predicted according to the reads in that sample.
subtype_by_sample <- subtype_by_sample %>% group_by(sample_label, segment) %>% slice_max(count,n = 1, with_ties = FALSE)

#Now split the subtype (ugly but works for now)
subtype_by_sample <- separate(subtype_by_sample, subtype, c("subH", "HA", "subN", "NA"), sep = "(?=[A-Za-z])(?<=[0-9])|(?=[0-9])(?<=[A-Za-z])", remove = F)

subtype_by_sample <- select(subtype_by_sample, !(c("subH", "subN")))

#Now need to reconstruct subtype from the match in each sample
subset(subtype_by_sample, segment == "4")$HA

#Get HA's
h <- subtype_by_sample %>% filter(segment == "4") %>% select(HA)
subset(h, select == "segment")
#Get NA's
n <- subtype_by_sample %>% filter(segment == "6") %>% select(`NA`)

subtypes_only <- subtypes_only[c(1,3,5)]

#Make a true subtype column
subtypes_only <- unite(subtypes_only, correct_subtype, c("HA", `NA`), sep = "_")

#Clean up with Grep
subtypes_only$correct_subtype <- gsub("^NA_", "H?N", subtypes_only$correct_subtype)
subtypes_only$correct_subtype <- gsub("_NA$", "N?", subtypes_only$correct_subtype)
#Add the N
subtypes_only$correct_subtype <- gsub("_", "N", subtypes_only$correct_subtype)

#Now add an H in front of all
subtypes_only$correct_subtype <- paste("H", subtypes_only$correct_subtype, sep = "")
#This is so hacky, it's delicious
subtypes_only$correct_subtype <- gsub("^HH", "H", subtypes_only$correct_subtype)

#Now merge to get sample info on the data frame 
subtypes_only <- left_join(subtypes_only, s21_swab_data)

#Calculate number of subtypes
subtypes_by_sample_total <- subtypes_only %>%
  group_by(correct_subtype, species, location) %>%
  summarise(n = n())

#Now plot!!
#Overall, coloring by species
ggplot(subtypes_by_sample_total, aes(x = correct_subtype, y = n, fill=species)) + geom_bar(aes(reorder(correct_subtype, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Predicted Subtype by FluDB Best Match") + coord_flip()

#Breakdown by location
ggplot(subtypes_by_sample_total, aes(x = correct_subtype, y = n, fill=species)) + geom_bar(aes(reorder(correct_subtype, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Predicted Subtype by FluDB Best Match") + coord_flip() + facet_wrap(~factor(location, levels=c("SAC_P4", "SAC_10.2", "DEL_T20.2")))

#Prevalence overall by location
sample_total <- s21_swab_data %>%
  group_by(location) %>%
  summarise(n = n())

sample_total <- subset(sample_total, !is.na(location))
colnames(sample_total) <- c("location", "total_samples") 

match_totals <- sequence_match_info_samples %>%
  group_by(location, sample_label) %>%
  summarise(n = n())

match_totals <- match_totals[1:2] %>% 
  group_by(location) %>%
  summarise(n = n())

prevalence_per_sample <- right_join(sample_total, match_totals)

#Nice plot of overall prevalence
ggplot(prevalence_per_sample, aes(x = location, y = n)) + geom_bar(aes(reorder(location, n), n), stat = "identity") + geom_errorbar(aes(y = total_samples, ymax = total_samples, ymin = total_samples)) + geom_text(aes(label = round(n/total_samples*100, digits = 2)), parse = TRUE, position = position_stack(0.95), vjust = 1, colour = "white") + ylab("Number of Samples") + xlab("Location")



