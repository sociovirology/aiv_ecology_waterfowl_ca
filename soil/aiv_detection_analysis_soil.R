# Script: aiv_detection_environment_analysis.R
# This file is an R script that couples sequencing information with sample information to arive at the main conclusions in the manuscript
# NOTE: This file depends on minion_demultiplexing_flu_assignment.sh. Run that script first!

#This script is part of the following manuscript:
#Analysis of MinION sequence data from water and sediment samples for avian influenza detection in California wetlands
#This github repository includes code (and links to data) from the manuscript:
#"Linking remote sensing for targeted surveillance of Avian Influenza virus via tangential flow ultra-filtration and whole segment amplification in California wetlands"
#Madeline M. McCuen | Maurice E. Pitesky | Ana Paula da Silva | Rodrigo A. Gallardo | Jeff J. Buler | Sarai Acosta | Alexander Wilcox | Ronald F. Bond | Samuel L. DÃ­az-MuÃ±oz

################ Avian Influenza Viruses Environment ################
#### 1. Data Sources and Preparing Data
#### 2. Analysis of Collected Samples
#### 3. Analysis of Sequencing Reads and FluDB Database Metadata 

#THIS CODE NEEDS FOLOWING FILES: 
# data/aiv_summer_2021_swab_demux.csv,
# data/aiv_summer_2021_swab_amott_edits.csv,
# demultiplexing_by_sample.txt - This file generated by script minion_demultiplexing_flu_assignment.sh
# avian_blast_matches.txt - This file generated by script minion_demultiplexing_flu_assignment.sh
# Individual sample *.out and *.tab files generated by script minion_demultiplexing_flu_assignment.sh

#Project Description
#Analysis of MinION sequence data from water and sediment samples for avian influenza detection in California wetlands
#Code for "Linking remote sensing for targeted surveillance of Avian Influenza virus via tangential flow ultra-filtration and whole segment amplification in California wetlands"
#Collaboration between Diaz-Munoz Lab and Madeline McCuen, Maurice Pitesky (PI), UC Davis

#Load libraries
library(readr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(ggthemes)
library(gridExtra)
library(reshape2)

#### 1. Data Sources and Preparing Data   ####

#Received a spreadsheet from Madeline McCuen via email on September 28, 2018 at 4:59pm
# entitled "AIV_filtration sample key 9_26_18.xlsx" Saved this file as CSV from Excel to import to R

setwd('/Users/mixtup/Dropbox/mixtup/Documentos/ucdavis/papers/aiv_waterfowl_california_central_valley_2021/aiv_ecology_waterfowl_ca/soil/')

#Import data from CSV, requires readr package
aiv_soil_summer_2021_demux <- read_csv("data/aiv_soil_summer_2021_demux.csv")
aiv_soil_summer_2021 <- read_csv("data/aiv_soil_summer_2021.csv")

#assign sample name by barcode:
aiv_soil_summer_2021_data <- left_join(aiv_soil_summer_2021_demux, aiv_soil_summer_2021)

#Now adding the number of reads recovered from demultiplexed files. Will add separate columns for number of reads that matched avian influenza genomes
demultiplexing_by_sample <- read.table("demultiplexing_by_sample.txt", quote="\"", comment.char="", col.names = c("reads", "barcode"))

#Clean up samples to make sample label match aiv_filtration
demultiplexing_by_sample$barcode <- gsub(".fast.", "", demultiplexing_by_sample$barcode)

aiv_soil_summer_2021_data <- left_join(aiv_soil_summer_2021_data, demultiplexing_by_sample)

#Removing NA's: carefully!!
aiv_soil_summer_2021_data$reads[is.na(aiv_soil_summer_2021_data$reads)] <- 0




#Now adding separate columns for number of reads that matched avian influenza genomes
avian_blast_matches <- read.table("avian_blast_matches.txt", quote="\"", comment.char="", col.names = c("matches", "barcode"))

#Clean up samples to make sample label match aiv_soil_summer_2021_data
avian_blast_matches$barcode <- gsub(".out", "", avian_blast_matches$barcode)

#Let's add to aiv_soil_summer_2021_data
aiv_soil_summer_2021_data <- left_join(aiv_soil_summer_2021_data, avian_blast_matches)

#Removing NA's: carefully!!
aiv_soil_summer_2021_data$matches[is.na(aiv_soil_summer_2021_data$matches)] <- 0


## END BONUS SECTION

#### 3. Analysis of Sequencing Reads and FluDB Database Metadata #### 

##First we need import and clean up data. 
#We'll start with importing information from .tab files, which contain metadata for the sequences in FluDB
file_names <- list.files(".", "*.tab")

metadata_avian <- NULL

for (i in 1:length(file_names)) {
  #import each file and add recursively to a data frame
  results <- read_delim(file_names[i], "|", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
  
  sample <- rep(file_names[i], nrow(results))
  results <- cbind(results, sample)
  
  metadata_avian <- rbind(metadata_avian, results)
}  

colnames(metadata_avian) <- c("gi", "organism", "strain", "segment", "subtype", "host", "barcode")

#Cleanup Data Frame Contents
metadata_avian$gi <- gsub(">*[A-z]*:", "", metadata_avian$gi)
metadata_avian$strain <- gsub("[A-z]*\\s[A-z]*:", "", metadata_avian$strain)
metadata_avian$organism <- gsub("[A-z]*:", "", metadata_avian$organism)
metadata_avian$segment <- gsub("[A-z]*:", "", metadata_avian$segment)
metadata_avian$subtype <- gsub("[A-z]*:", "", metadata_avian$subtype)
metadata_avian$host <- gsub("[A-z]*:", "", metadata_avian$host)

metadata_avian$barcode <- gsub("*.tmp.tab", "", metadata_avian$barcode)


#View(metadata_avian)
#View(right_join(metadata_avian, aiv_filtration))

#leaves samples with no matches at bottom....? 
metadata_avian <- right_join(metadata_avian, aiv_soil_summer_2021_data)

#Fix the mixed subtypes category
metadata_avian$subtype <- gsub("Mixed", "mixed", metadata_avian$subtype)

#Make a new data frame excluding positive control samples
metadata_avian_samples <- subset(metadata_avian, sample_label != "pos" & sample_label != "neg")

#Now that we're done with metadata, let's bring in the sequence matching information and pair it with the segment information
file_list <- list.files(".", "*.out")

sequence_match_info <- NULL

for (i in 1:length(file_list)) {
  #import each file and add recursively to a data frame
  results <- read_delim(file_list[i], "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
  #colnames(results) <- c("qid", "match", "percent_id", "alignment_length", "mismatches", "gap_opens", "start_query", "end_query", "start_target", "end_target", "evalue", "bitscore")
  
  sample <- rep(file_list[i], nrow(results))
  results <- cbind(results, sample)
  
  sequence_match_info <- rbind(sequence_match_info, results)
}

nrow(sequence_match_info)
#[1] 155743

colnames(sequence_match_info) <- c("qid", "match", "percent_id", "alignment_length", "mismatches", "gap_opens", "start_query", "end_query", "start_target", "end_target", "evalue", "bitscore", "barcode")

#Clean up sample name
sequence_match_info$barcode <- gsub("*.out", "", sequence_match_info$barcode)

#Extract GB to match
sequence_match_info$match <- gsub("gb:", "", sequence_match_info$match)
sequence_match_info$match <- gsub("\\|[A-z]*:[A-z]*", "", sequence_match_info$match)

#Adjust colnames for join
colnames(sequence_match_info) <- c("qid", "gi", "percent_id", "alignment_length", "mismatches", "gap_opens", "start_query", "end_query", "start_target", "end_target", "evalue", "bitscore", "barcode")

#How many sequences left
nrow(sequence_match_info)
#[1] 155743

#Remove Positive Controls (test)
#View(subset(sequence_match_info, `Sample Label` != "PR8 RNA A" & `Sample Label` != "PR8 RNA B"))

#Already removed positives, but changing name so it matches code below
sequence_match_info_samples <- subset(sequence_match_info, barcode != "barcode01")


##Now we can get down to analyses. #These are reported in manuscripts under Results: "Sequencing Data and AIv Database Match Summary"

#Mean alignment length across all segments
mean(sequence_match_info_samples$alignment_length)
#[1] 826.6745

#Number of segments with alignment length over 2.2kpbs
nrow(subset(sequence_match_info_samples, alignment_length > 2200))
#[1] 35

#Of those, how many are > 2.3kpbs?
nrow(subset(sequence_match_info_samples, alignment_length > 2300))
#[1] 28

#Accuracy?
mean(subset(sequence_match_info_samples, alignment_length > 2300)$percent_id)
#[1] 94.38461

#Mean alignment length
mean(sequence_match_info_samples$alignment_length)
#826.6745
sd(sequence_match_info_samples$alignment_length)
#279.4987
length(sequence_match_info_samples$alignment_length)
#[1] 134179

#Mean percentage identity
mean(sequence_match_info_samples$percent_id)
#[1] 96.01979
sd(sequence_match_info_samples$percent_id)
#[1] 2.859291
length(sequence_match_info_samples$percent_id)
#[1] 134179

#Histogram of PID matches
hist(sequence_match_info_samples$percent_id)

#Now we want to add sequence match metadata, but only to existing records
metadata_avian_distinct <- distinct(metadata_avian, gi, .keep_all = TRUE)

#Get only the info from the IRD database
metadata_avian_distinct <- subset(metadata_avian_distinct, select = c("gi", "organism", "strain", "segment", "subtype", "host"))

#Test Join
#View(inner_join(sequence_match_info_samples, metadata_avian_distinct, by = "gi"))

#Join
sequence_match_info_samples <- inner_join(sequence_match_info_samples, metadata_avian_distinct, by = "gi")

#Test if I affected anything with join
mean(sequence_match_info_samples$alignment_length)
#[1] 826.6798
#Ish???! Check later

#What is the segment match distribution
#These results are repoted in Table 2 in manuscript and also in text 
table(sequence_match_info_samples$segment)
#1     2     3     4     5     6     7     8 
#9858  1331  6765   316  3234  3273 48334 61067

#How many samples have at least 1 M segment match? This is to compare to RT-qPCR results.
table(subset(sequence_match_info_samples, segment == 7, select = barcode))
#barcode04 barcode05 barcode06 barcode07 barcode09 barcode10 barcode11 barcode12 barcode14 barcode21 
#545       439         1       136        14        77      2257       914         2         8 
#barcode22 barcode23 barcode24 barcode30 barcode31 barcode33 barcode34 barcode35 barcode36 barcode38 
#374      1268      2359         2       328       258        40       490      3701         1 
#barcode39 barcode40 barcode42 barcode43 barcode45 barcode46 barcode47 barcode48 barcode50 barcode54 
#2      3873         2        13       578       835       342      1633         1       121 
#barcode57 barcode59 barcode60 barcode62 barcode63 barcode64 barcode65 barcode66 barcode67 barcode68 
#668      3658       422         1       314        56        69        24       305        92 
#barcode69 barcode70 barcode71 barcode72 barcode74 barcode75 barcode76 barcode78 barcode79 barcode80 
#4        83      6198      1296         2         2      1644       124         4         3 
#barcode81 barcode82 barcode83 barcode84 barcode88 barcode89 barcode91 barcode93 barcode94 barcode95 
#621       420      1011      6469        14         5        25        30        39      1577 
#barcode96 
#2540  

nrow(table(subset(sequence_match_info_samples, segment == 7, select = barcode)))
#[1] 61
#So if I only count M segment matches as positives by sequencing, I would have 15 positive samples vs 19 if I count any segment (see code below)
#This result is reported in Results: Whole-segment amplification/sequencing yielded more positive samples than M-segment RT-qPCR

#We count as positive the samples that had at least one read matching avian influenza virus genomes database
table(aiv_soil_summer_2021_data[,]$matches > 0)
#FALSE  TRUE 
#15    81
#Need to subtract positive control from this one!

#Are they largely the same samples?
#barcode04 barcode05 barcode06 barcode09 barcode11 barcode12 barcode16 barcode17 barcode18 barcode22 barcode24 barcode28 barcode29 barcode32 
#1         1         1         1         1         1         1         1         1         1         1         1         1         1 
#barcode34 barcode35 barcode36 barcode37 barcode39 barcode40 barcode42 barcode47 barcode48 barcode51 barcode52 barcode53 barcode57 barcode58 
#1         1         1         1         1         1         1         1         1         1         1         1         1         1 
#barcode61 barcode64 barcode66 barcode69 barcode70 barcode71 barcode73 barcode74 barcode75 barcode76 barcode77 barcode81 barcode84 barcode85 
#1         1         1         1         1         1         1         1         1         1         1         1         1         1 
#barcode88 barcode89 barcode93 barcode94 barcode96 
#1         1         1         1         1 

#Yep! Including all read matches added 4 positives: A5 SW Unfltrd, B2 Fltrd RXD, C1 Fltrd RXD, and C1 SW Unfltrd 

#Is there any evidence of identical or similar sequences across samples? No. See analysis in checking_similar_sequences.sh

#Let's do a quick sanity check that this is all working properly
#One way to check is to look at reads here vs AIV filtration

#How many  matches do I have here compared to the original aiv_filtration dataframe?
sequence_check <- group_by(sequence_match_info_samples, barcode) %>%
  summarise(
    count = n(),
  )
#aiv_filtration_check  <- subset(aiv_soil_summer_2021_data, filtration != "NA" & matches > 0, select = c("Sample Label", "avian_read_matches"))
aiv_soil_summer_2021_data_check  <- subset(aiv_soil_summer_2021_data, matches > 0, select = c("barcode", "matches"))

#Join
check <- inner_join(aiv_soil_summer_2021_data_check, sequence_check)
which(check$matches != check$matches)
#integer(0)
#They're the same, we're good

#Check out distribution of subtypes
sequence_match_info_samples_subtypes <- subset(sequence_match_info_samples, segment == 4 | segment == 6)

#Filter out short matches
sequence_match_info_samples_subtypes_over500 <- subset(sequence_match_info_samples_subtypes, alignment_length > 500)

#Overall subtype distribution Figure 7 in the text
figure7 <- ggplot(sequence_match_info_samples_subtypes, aes(x = subtype, fill = segment)) + geom_histogram(stat = "count") + scale_y_log10() + coord_flip() 
figure7
#ggsave("figure7.pdf", figure7)

#Overall subtype distribution by location
ggplot(sequence_match_info_samples_subtypes, aes(x = subtype, fill = segment)) + geom_histogram(stat = "count") + scale_y_log10() + coord_flip() + facet_wrap(~ location) 


#Sumary stats
group_by(sequence_match_info_samples_subtypes, segment, subtype) %>%
  summarise(
    count = n(),
    mean_alignment = mean(alignment_length)
  )
# A tibble: 6 × 4
# Groups:   segment [2]
#segment subtype count mean_alignment
#<chr>   <chr>   <int>          <dbl>
#  1 4       H1N1      316           610.
#2 6       H10N1       3          1436.
#3 6       H1N1     3266          1182.
#4 6       H5N1        1          1440 
#5 6       H6N1        2          1434 
#6 6       H7N1        1          1437

#Now let's look at hosts
#Let's add location
#location <- NULL
#location[grep("^A", sequence_match_info_samples$`Sample Label`)] <- "A. Butte county wetland"
#location[grep("^B", sequence_match_info_samples$`Sample Label`)] <- "B. Yolo bypass wildlife area"
#location[grep("^C", sequence_match_info_samples$`Sample Label`)] <- "C. Yolo bypass wildlife area"

sequence_match_info_samples_subtypes <- left_join(sequence_match_info_samples_subtypes, aiv_soil_summer_2021_data, by='barcode')
sequence_match_info_samples <- left_join(sequence_match_info_samples, aiv_soil_summer_2021_data, by='barcode')



#Let's clean up the repeat names due to minor mispellings
table(sequence_match_info_samples$host)

sequence_match_info_samples$host <- gsub("Blue Winged Teal", "Blue-Winged Teal", sequence_match_info_samples$host)
sequence_match_info_samples$host <- gsub("American Green-Winged Teal", "Green-Winged Teal", sequence_match_info_samples$host)
sequence_match_info_samples$host <- gsub("^Pintail$", "Northern Pintail", sequence_match_info_samples$host)

#Test
#View(cbind(sequence_match_info_samples, location))

#sequence_match_info_samples <- cbind(sequence_match_info_samples, location)

group_by(sequence_match_info_samples, segment) %>%
  summarise(
    count = n(),
    mean = mean(percent_id, na.rm = TRUE),
    sd = sd(percent_id, na.rm = TRUE)
  )
# A tibble: 8 Ã 4
# A tibble: 8 × 4
#segment count  mean    sd
#<chr>   <int> <dbl> <dbl>
#  1 1        9858  96.4  3.08
#2 2        1331  95.6  3.43
#3 3        6765  95.9  2.86
#4 4         316  95.9  2.97
#5 5        3234  95.8  2.75
#6 6        3273  95.8  2.77
#7 7       48334  96.0  2.99
#8 8       61067  96.1  2.70


group_by(sequence_match_info_samples, segment) %>%
  summarise(
    count = n(),
    mean = mean(alignment_length, na.rm = TRUE),
    sd = sd(alignment_length, na.rm = TRUE)
  )
#  segment count  mean    sd
#<chr>   <int> <dbl> <dbl>
#  1 1        9858  278. 154. 
#2 2        1331  324. 316. 
#3 3        6765  292.  88.9
#4 4         316  610. 525. 
#5 5        3234  962. 423. 
#6 6        3273 1182. 438. 
#7 7       48334  951. 196. 
#8 8       61067  862.  76.6

#Now look at hosts of the sequences matched in the database
host_counts_sequence_match <- subset(sequence_match_info_samples, alignment_length > 500) %>%
  group_by(host) %>%
  summarise(n = n())

#Hosts overall, ordered. This is main panel in Figure 8 in the text
figure8 <- ggplot(host_counts_sequence_match, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip()
figure8
#ggsave("figure8.pdf", figure8)


#Ok. Now Plot the Hosts, but by site
#Make a data frame by site ordered
host_counts_site_sequence_match <-subset(sequence_match_info_samples, alignment_length > 500) %>%
  group_by(host, `Wildlife Management Unit`) %>%
  summarise(n = n())

#Plot by site ordered
ggplot(host_counts_site_sequence_match, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip() + facet_wrap(~ `Wildlife Management Unit`, scales = "free_x")

#For Brock Presentation: Plot by sample, subdivided by site
ggplot(host_counts_site_sequence_match, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip() + facet_wrap(~ `Wildlife Management Unit`, scales = "free_x")

#By Site ordered, exclude hosts that are only represented by 1 or 2 matches
figure8_inset <- ggplot(subset(host_counts_site_sequence_match, n > 2), aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip() + facet_wrap(~ `Wildlife Management Unit`, scales = "free_x")
figure8_inset
#ggsave("figure8_inset.pdf", figure8_inset)



#Excluding hosts predicted by just a few reads
ggplot(subset(host_counts_site_sequence_match, n > 2), aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + coord_flip()









## These summary statistics are found in paper under Results: "California Wetlands Harbor Avian Viruses from Multiple Potential Host Origins and Subtypes"  
#Total host matches that have 
sum(host_counts_sequence_match$n)
#[1] 111630

#How many hosts identified? Remember this dataframe is grouped by hosts so, rows == # of hosts
nrow(host_counts_sequence_match)
#[1] 53

#Sort hosts and get the percentage of total matches by the top 5 hosts
(sort(host_counts_sequence_match$n, decreasing = TRUE)[1:5] / sum(host_counts_sequence_match$n))*100
#[1]  98.65806683  0.51688614  0.32518140  0.09853982  0.09047747

#Top 5 summed percentages
sum(sort(host_counts_sequence_match$n, decreasing = TRUE)[1:5] / sum(host_counts_sequence_match$n))*100
#[1] 99.68915





#courtney added plots



ggplot(data=sequence_match_info_samples, aes(sample_label, segment))+
  geom_point()

#Modification of above to show number of segments in samples
ggplot(data=sequence_match_info_samples, aes(sample_label, as.factor(segment), fill=segment)) +
  geom_bar(position = "fill",stat = "identity") + coord_flip()

ggplot(data=sequence_match_info_samples, aes(segment, fill=segment)) +
  geom_bar(position = "fill") + facet_wrap(~ sample_label, scales = "free_y")
number_segments_sample <- ggplot(data=sequence_match_info_samples, aes(segment, fill=segment)) + geom_bar(position = "fill") + facet_wrap(~ sample_label, scales = "free_y")
ggsave("soil_figures/number_segments_sample.pdf", number_segments_sample)


ggplot(data=sequence_match_info_samples, aes(`Wildlife Management Unit`, subtype))+
  geom_col()

ggplot(data=sequence_match_info_samples, aes(fill=subtype, x=`Wildlife Management Unit`, y=subtype))+
  geom_point()

#### 4. Prevalence and BLAST Matching Stats #### 

#Number of reads per sample, colored by species
ggplot(data=aiv_soil_summer_2021_data, aes(x=reorder(barcode, reads), y=reads)) + geom_col() + coord_flip()
read_prevalence <- ggplot(data=aiv_soil_summer_2021_data, aes(x=reorder(barcode, reads), y=reads)) + geom_col() + coord_flip()
ggsave("soil_figures/read_prevalence.pdf", read_prevalence)

#Number of reads matchig the flu database per sample
ggplot(data=subset(aiv_soil_summer_2021_data, sample_label != "pos"), aes(x=reorder(sample_label, matches), y=matches)) + geom_col() + coord_flip()
match_prevalence <- ggplot(data=subset(aiv_soil_summer_2021_data, sample_label != "pos"), aes(x=reorder(sample_label, matches), y=matches)) + geom_col() + coord_flip()
ggsave("soil_figures/match_prevalence.pdf", match_prevalence)

#Prevalence per site
ggplot(data=subset(aiv_soil_summer_2021_data, `Wildlife Management Unit` != "NA"), aes(fill=sample_label, x= `Wildlife Management Unit`, y=matches)) + geom_col() + theme(legend.position = "none")
#Summary_Stats
#summarise()

ggplot(data=aiv_soil_summer_2021_data, aes(x=reorder(species, matches), y=matches)) + geom_col() + coord_flip() + scale_y_log10()


#Plots for Brock Presentation 

#Host by sample
hosts_by_sample <- group_by(sequence_match_info_samples, sample_label, strain, host, `Wildlife Management Unit`) %>%
  summarise(
    count = n(),
    mean_align = mean(alignment_length, na.rm = TRUE),
    sd_align = sd(alignment_length, na.rm = TRUE),
    mean_id = mean(percent_id, na.rm = TRUE),
    sd_id = sd(percent_id, na.rm = TRUE)
  )

View(hosts_by_sample)

#This tells me the top host predicted according to the reads in that sample.
hosts_by_sample <- hosts_by_sample %>% group_by(sample_label) %>% slice_max(count,n = 1, with_ties = FALSE)

#Plot by site
hosts_by_sample_location <- hosts_by_sample %>%
  group_by(host, `Wildlife Management Unit`) %>%
  summarise(n = n())

#Plot
ggplot(hosts_by_sample_location, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Closest Predicted Host by FluDB Best Match") + coord_flip() + facet_wrap(~factor(`Wildlife Management Unit`))

#Plot overall
hosts_by_sample_total <- hosts_by_sample %>%
  group_by(host) %>%
  summarise(n = n())

#Plot predicted 
ggplot(hosts_by_sample_location, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Closest Predicted Host by FluDB Best Match") + coord_flip()
predicted_hosts_overall <- ggplot(hosts_by_sample_location, aes(x = host, y = n)) + geom_bar(aes(reorder(host, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Closest Predicted Host by FluDB Best Match") + coord_flip()
ggsave("soil_figures/predicted_hosts_overall.pdf", predicted_hosts_overall)

#Subtype by sample
subtype_by_sample <- group_by(subset(sequence_match_info_samples, segment == "4" | segment == "6"), sample_label, segment, subtype, host, `Wildlife Management Unit`) %>%
  summarise(
    count = n(),
    mean_align = mean(alignment_length, na.rm = TRUE),
    sd_align = sd(alignment_length, na.rm = TRUE),
    mean_id = mean(percent_id, na.rm = TRUE),
    sd_id = sd(percent_id, na.rm = TRUE)
  )

View(subtype_by_sample)

#This tells me the top host predicted according to the reads in that sample.
subtype_by_sample <- subtype_by_sample %>% group_by(sample_label, segment) %>% slice_max(count,n = 1, with_ties = FALSE)

#Now split the subtype (ugly but works for now)
subtype_by_sample <- separate(subtype_by_sample, subtype, c("subH", "HA", "subN", "NA"), sep = "(?=[A-Za-z])(?<=[0-9])|(?=[0-9])(?<=[A-Za-z])", remove = F)

subtype_by_sample <- select(subtype_by_sample, !(c("subH", "subN")))

#Now need to reconstruct subtype from the match in each sample
subset(subtype_by_sample, segment == "4")$HA

#Get HA's
h <- subtype_by_sample %>% filter(segment == "4") %>% select(HA)
subset(h, select == "segment")
#Get NA's
n <- subtype_by_sample %>% filter(segment == "6") %>% select(`NA`)

subtypes_only <- subtypes_only[c(1,3,5)]

#Make a true subtype column
subtypes_only <- unite(subtypes_only, correct_subtype, c("HA", `NA`), sep = "_")

#Clean up with Grep
subtypes_only$correct_subtype <- gsub("^NA_", "H?N", subtypes_only$correct_subtype)
subtypes_only$correct_subtype <- gsub("_NA$", "N?", subtypes_only$correct_subtype)
#Add the N
subtypes_only$correct_subtype <- gsub("_", "N", subtypes_only$correct_subtype)

#Now add an H in front of all
subtypes_only$correct_subtype <- paste("H", subtypes_only$correct_subtype, sep = "")
#This is so hacky, it's delicious
subtypes_only$correct_subtype <- gsub("^HH", "H", subtypes_only$correct_subtype)

#Now merge to get sample info on the data frame 
subtypes_only <- left_join(subtypes_only, aiv_soil_summer_2021_data)

#Calculate number of subtypes
subtypes_by_sample_total <- subtypes_only %>%
  group_by(correct_subtype, location) %>%
  summarise(n = n())

#Now plot!!
#Overall, coloring by species
ggplot(subtypes_by_sample_total, aes(x = correct_subtype, y = n, fill=species)) + geom_bar(aes(reorder(correct_subtype, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Predicted Subtype by FluDB Best Match") + coord_flip()

#Breakdown by location
ggplot(subtypes_by_sample_total, aes(x = correct_subtype, y = n, fill=species)) + geom_bar(aes(reorder(correct_subtype, n), n), stat = "identity") + ylab("Number of Samples") + xlab("Predicted Subtype by FluDB Best Match") + coord_flip() + facet_wrap(~factor(location, levels=c("SAC_P4", "SAC_10.2", "DEL_T20.2")))

#Prevalence overall by location
sample_total <- aiv_soil_summer_2021_data %>%
  group_by(`Wildlife Management Unit`) %>%
  summarise(n = n())

sample_total <- subset(sample_total, !is.na(`Wildlife Management Unit`))
colnames(sample_total) <- c("location", "total_samples") 

match_totals <- sequence_match_info_samples %>%
  group_by(`Wildlife Management Unit`, sample_label) %>%
  summarise(n = n())

colnames(match_totals) <- c("location", "sample_label", "n")

match_totals <- match_totals[1:2] %>% 
  group_by(location) %>%
  summarise(n = n())

prevalence_per_sample <- right_join(sample_total, match_totals)

#Nice plot of overall prevalence
ggplot(prevalence_per_sample, aes(x = location, y = n)) + geom_bar(aes(reorder(location, n), n), stat = "identity") + geom_errorbar(aes(y = total_samples, ymax = total_samples, ymin = total_samples)) + geom_text(aes(label = round(n/total_samples*100, digits = 2)), parse = TRUE, position = position_stack(0.95), vjust = 1, colour = "white") + ylab("Number of Samples") + xlab("Location")
overall_prevalence_location <- ggplot(prevalence_per_sample, aes(x = location, y = n)) + geom_bar(aes(reorder(location, n), n), stat = "identity") + geom_errorbar(aes(y = total_samples, ymax = total_samples, ymin = total_samples)) + geom_text(aes(label = round(n/total_samples*100, digits = 2)), parse = TRUE, position = position_stack(0.95), vjust = 1, colour = "white") + ylab("Number of Samples") + xlab("Location")
ggsave("soil_figures/overall_prevalence_location.pdf", overall_prevalence_location)


#Prevalence overall by low/hi
sample_total_use_level <- aiv_soil_summer_2021_data %>%
  group_by(`Use Level`) %>%
  summarise(n = n())

sample_total_use_level <- subset(sample_total_use_level, !is.na(`Use Level`))
colnames(sample_total_use_level) <- c("Use Level", "total_samples") 

match_totals_use_level <- sequence_match_info_samples %>%
  group_by(`Use Level`, sample_label) %>%
  summarise(n = n())

match_totals_use_level <- match_totals_use_level[1:2] %>% 
  group_by(`Use Level`) %>%
  summarise(n = n())

prevalence_use_level <- right_join(sample_total_use_level, match_totals_use_level)

#Can do a quick prop test here to test the differences
prop.test(c(44, 35), c(49, 45))
#2-sample test for equality of proportions with continuity correction

#data:  c(44, 35) out of c(49, 45)
#X-squared = 1.7097, df = 1, p-value = 0.191
#alternative hypothesis: two.sided
#95 percent confidence interval:
#  -0.04924855  0.28961136
#sample estimates:
#  prop 1    prop 2 
#0.8979592 0.7777778


#Nice plot of overall prevalence
ggplot(prevalence_use_level, aes(x = `Use Level`, y = n)) + geom_bar(aes(reorder(`Use Level`, n), n), stat = "identity") + geom_errorbar(aes(y = total_samples, ymax = total_samples, ymin = total_samples)) + geom_text(aes(label = round(n/total_samples*100, digits = 2)), parse = TRUE, position = position_stack(0.95), vjust = 1, colour = "white") + ylab("Number of Samples") + xlab("Use Level")
overall_prevalence_use_level <- ggplot(prevalence_use_level, aes(x = `Use Level`, y = n)) + geom_bar(aes(reorder(`Use Level`, n), n), stat = "identity") + geom_errorbar(aes(y = total_samples, ymax = total_samples, ymin = total_samples)) + geom_text(aes(label = round(n/total_samples*100, digits = 2)), parse = TRUE, position = position_stack(0.95), vjust = 1, colour = "white") + ylab("Number of Samples") + xlab("Use Level")
ggsave("soil_figures/overall_prevalence_use_level.pdf", overall_prevalence_use_level)


